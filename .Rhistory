install.packages(c("caret", "clusterSim", "dplyr", "e1071", "ggplot2", "rstudioapi"))
# Tiempo dedicado a la entrega:
# Dificultades encontradas y manera de resolverlas:
##---------------------------------------------------------------------------
# 1. AsegÃƒÂºrese de incluir, junto a esta plantilla, cualquier fichero necesario
#    para su ejecuciÃƒÂ³n, incluidos datasets
# 2. Si utiliza una funciÃƒÂ³n de un determinado paquete, no olvide incluir la
#    correspondiente llamada a la funciÃƒÂ³n "library()"
# 3. No olvide comentar el cÃƒÂ³digo, en especial aquellos comandos no-triviales
#    (recuerda que parte de la calificaciÃƒÂ³n depende de la limpieza del cÃƒÂ³digo)
#---------------------------------------------------------------------------
rm(list = ls());cat("\014")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# (incluya aquÃƒ­ cualquier librerÃƒ­a a utilizar)
library(dplyr)
library(lattice)
library(ggplot2)
library(caret)
library(e1071)
library(clusterSim)
library(class)
#---------------------------------------------------------------------------
######################## Parte 1 ###########################################
#---------------------------------------------------------------------------
# Paso 1: Utilice la funciÃƒÂ³n read.csv para leer el contenido del fichero "movie_metadata.csv"
#     AdemÃƒÂ¡s, elimine las siguientes columnas: "director_name", "actor_2_name", "actor_1_name"
#     "movie_title", "plot_keywords", "movie_imdb_link"
# ** Puede automatizar el proceso si intenta eliminar todas las columnas que sean de
#    tipo factor, y que ademÃƒÂ¡s, tengan mÃƒÂ¡s de 100 niveles diferentes
datos = read.csv("datos/movie_metadata.csv")
datos = dplyr::select(datos, -director_name, -actor_2_name, -actor_1_name, -movie_title, -plot_keywords, -movie_imdb_link)
# Paso 2: Discretice la columna imbd_score para tener rangos en [0, 7.5) [7.5, 9) y [9, 10]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
library(arules)
#---------------------------------------------------------------------------
######################## Parte 1 ###########################################
#---------------------------------------------------------------------------
# Paso 1: Utilice la funciÃƒÂ³n read.csv para leer el contenido del fichero "movie_metadata.csv"
#     AdemÃƒÂ¡s, elimine las siguientes columnas: "director_name", "actor_2_name", "actor_1_name"
#     "movie_title", "plot_keywords", "movie_imdb_link"
# ** Puede automatizar el proceso si intenta eliminar todas las columnas que sean de
#    tipo factor, y que ademÃƒÂ¡s, tengan mÃƒÂ¡s de 100 niveles diferentes
datos = read.csv("datos/movie_metadata.csv")
datos = dplyr::select(datos, -director_name, -actor_2_name, -actor_1_name, -movie_title, -plot_keywords, -movie_imdb_link)
# Paso 2: Discretice la columna imbd_score para tener rangos en [0, 7.5) [7.5, 9) y [9, 10]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
library(arules)
library(arules)
install.packages("arules", dependencies = TRUE)
# (incluya aquÃƒ­ cualquier librerÃƒ­a a utilizar)
library(dplyr)
library(lattice)
library(ggplot2)
library(caret)
library(e1071)
library(clusterSim)
library(class)
library(arules)
#---------------------------------------------------------------------------
######################## Parte 1 ###########################################
#---------------------------------------------------------------------------
# Paso 1: Utilice la funciÃƒÂ³n read.csv para leer el contenido del fichero "movie_metadata.csv"
#     AdemÃƒÂ¡s, elimine las siguientes columnas: "director_name", "actor_2_name", "actor_1_name"
#     "movie_title", "plot_keywords", "movie_imdb_link"
# ** Puede automatizar el proceso si intenta eliminar todas las columnas que sean de
#    tipo factor, y que ademÃƒÂ¡s, tengan mÃƒÂ¡s de 100 niveles diferentes
datos = read.csv("datos/movie_metadata.csv")
datos = dplyr::select(datos, -director_name, -actor_2_name, -actor_1_name, -movie_title, -plot_keywords, -movie_imdb_link)
# Paso 2: Discretice la columna imbd_score para tener rangos en [0, 7.5) [7.5, 9) y [9, 10]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
View(datos)
# Paso 3: QuÃƒÂ©date ÃƒÂºnicamente con las filas que tienen todos los datos (no tienen NAs)
datos = na.omit(datos)
# Paso 4: utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#         en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
datostst = datos[-trainIndex,]
# Paso 5: Llame a la funciÃƒÂ³n naiveBayes, de la librerÃƒ­a "e1071" para entrenar el modelo con los
# datos de entrenamiento (datostra)
# --> modelo1=naiveBayes(........)
modelo1 = naiveBayes(imdb_score ~ ., datostra, laplace = 0)
# Paso 6: Llame a la funciÃƒÂ³n naiveBayes para entrenar un modelo2, utilizando el parÃƒÂ¡metro que aplica
# la correcciÃƒÂ³n de Laplace
# --> modelo2=naiveBayes(...)
modelo2 = naiveBayes(imdb_score ~ ., datostra, laplace = 3)
# Paso 7: Realice predicciones sobre los datos de test (datostst) de los dos modelos con el comando predict
# --> prediccion1=predict(modelo1,...)
# --> prediccion2=predict(modelo2,...)
prediccion1 = predict(modelo1, datostst)
prediccion2 = predict(modelo2, datostst)
table(prediccion1)
table(prediccion2)
# Paso 8: Calcule el porcentaje de aciertos de cada uno de los modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, datostst$imdb_score)
View(aciertosModelo1)
aciertosModelo2 = confusionMatrix(prediccion2, datostst$imdb_score)
aciertosModelo1
aciertosModelo2
#---------------------------------------------------------------------------
######################## Parte 2 ###########################################
#---------------------------------------------------------------------------
# Paso 1: Utilice la funciÃƒÂ³n read.csv para leer el contenido del fichero "movie_metadata.csv" (igual que antes)
# En este caso, elimine toda columna que no sea numÃƒÂ©rica y toda fila que tenga algÃƒÂºn valor perdido.
# Discretice la columna imbd_score igual que antes
# * Puede utilizar los comandos is.numeric()
# * EstÃƒÂ¡ permitido eliminar "manualmente" las columnas, pero no es elegante
datos = read.csv("datos/movie_metadata.csv")
datos = na.omit(datos)
datos = datos[,sapply(datos, is.numeric)]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
# Paso 2: Cree una copia de los datos llamada "datosnor" y normalizela
# * Puede usar la funciÃƒÂ³n "data.Normalization()", dentro del paquete "clusterSim"
# * ojo, lea la documentaciÃƒÂ³n para ver quÃƒÂ© valor tiene que darle al parÃƒÂ¡metro "type"
# * Cuidado, te darÃƒÂ¡ error si intentas normalizarlo todo, ya que imbd_score no es numÃƒÂ©rica
index = match("imdb_score", names(datos))
datosnor = datos[,-index]
datosnor = data.Normalization(datosnor,"n8","column")
datosnor$imdb_score = datos$imdb_score;
# Paso 3: (igual que antes) utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#   en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
# * Ojo, para ejecutar KNN la clase tiene que estar por un lado, y la columna a predecir separada, por otro
# * por ello, deberÃƒÂ¡ partir datostra en [datostra, con todas las columnas, salvo imbd_score] [labeltra, con ÃƒÂºnicamente la columna imbd_score]
# * (idem para datostst), y tenga en cuenta que debe realizar el mismo proceso con datosnor
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
labeltra = matrix(datostra$imdb_score)
index = match("imdb_score", names(datostra))
datostra = datostra[,-index]
datostst = datos[-trainIndex,]
labeltst = matrix(datostst$imdb_score)
index = match("imdb_score", names(datostst))
datostst = datostst[,-index]
trainIndex = createDataPartition(datosnor$duration, times = 1, p = 0.8, list = FALSE)
datostranor = datosnor[trainIndex,]
labeltranor = matrix(datostranor$imdb_score)
index = match("imdb_score", names(datostranor))
datostranor = datostranor[,-index]
datoststnor = datosnor[-trainIndex,]
labeltstnor = matrix(datoststnor$imdb_score)
index = match("imdb_score", names(datoststnor))
datoststnor = datoststnor[,-index]
# Paso 4: Aplique KNN con 3 valores de K diferentes (a su elecciÃƒÂ³n), para los datos normalizados y sin normalizar
# --> prediccion1 = knn(datostra, datostst, labeltra, k = XX)
# --> prediccion2 = knn(datostranor, datoststnor, labeltranor, k = XX)
# (hasta 6)
prediccion1 = knn(datostra, datostst, labeltra, k=10)
prediccion2 = knn(datostra, datostst, labeltra, k=1)
prediccion3 = knn(datostra, datostst, labeltra, k=5)
table(prediccion1)
table(prediccion2)
table(prediccion3)
prediccion4 = knn(datostranor, datoststnor, labeltranor, k=10)
prediccion5 = knn(datostranor, datoststnor, labeltranor, k=1)
prediccion6 = knn(datostranor, datoststnor, labeltranor, k=5)
table(prediccion4)
table(prediccion5)
table(prediccion6)
# Paso 5: Calcule el porcentaje de aciertos de cada uno de los 6 modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, labeltra)
# Paso 5: Calcule el porcentaje de aciertos de cada uno de los 6 modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, labeltra)
aciertosModelo2 = confusionMatrix(prediccion2, labeltra)
#    tipo factor, y que ademÃƒÂ¡s, tengan mÃƒÂ¡s de 100 niveles diferentes
datos = read.csv("datos/movie_metadata.csv")
datos = dplyr::select(datos, -director_name, -actor_2_name, -actor_1_name, -movie_title, -plot_keywords, -movie_imdb_link)
# Paso 2: Discretice la columna imbd_score para tener rangos en [0, 7.5) [7.5, 9) y [9, 10]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
# Paso 3: QuÃƒÂ©date ÃƒÂºnicamente con las filas que tienen todos los datos (no tienen NAs)
datos = na.omit(datos)
# Paso 4: utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#         en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
datostst = datos[-trainIndex,]
# Paso 5: Llame a la funciÃƒÂ³n naiveBayes, de la librerÃƒ­a "e1071" para entrenar el modelo con los
# datos de entrenamiento (datostra)
# --> modelo1=naiveBayes(........)
modelo1 = naiveBayes(imdb_score ~ ., datostra, laplace = 0)
# Paso 6: Llame a la funciÃƒÂ³n naiveBayes para entrenar un modelo2, utilizando el parÃƒÂ¡metro que aplica
# la correcciÃƒÂ³n de Laplace
# --> modelo2=naiveBayes(...)
modelo2 = naiveBayes(imdb_score ~ ., datostra, laplace = 3)
# Paso 7: Realice predicciones sobre los datos de test (datostst) de los dos modelos con el comando predict
# --> prediccion1=predict(modelo1,...)
# --> prediccion2=predict(modelo2,...)
prediccion1 = predict(modelo1, datostst)
prediccion2 = predict(modelo2, datostst)
table(prediccion1)
table(prediccion2)
# Paso 8: Calcule el porcentaje de aciertos de cada uno de los modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, datostst$imdb_score)
aciertosModelo2 = confusionMatrix(prediccion2, datostst$imdb_score)
aciertosModelo1
aciertosModelo2
datos = read.csv("datos/movie_metadata.csv")
datos = na.omit(datos)
datos = datos[,sapply(datos, is.numeric)]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
# Paso 2: Cree una copia de los datos llamada "datosnor" y normalizela
# * Puede usar la funciÃƒÂ³n "data.Normalization()", dentro del paquete "clusterSim"
# * ojo, lea la documentaciÃƒÂ³n para ver quÃƒÂ© valor tiene que darle al parÃƒÂ¡metro "type"
# * Cuidado, te darÃƒÂ¡ error si intentas normalizarlo todo, ya que imbd_score no es numÃƒÂ©rica
index = match("imdb_score", names(datos))
datosnor = datos[,-index]
datosnor = data.Normalization(datosnor,"n8","column")
datosnor$imdb_score = datos$imdb_score;
# Paso 3: (igual que antes) utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#   en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
# * Ojo, para ejecutar KNN la clase tiene que estar por un lado, y la columna a predecir separada, por otro
# * por ello, deberÃƒÂ¡ partir datostra en [datostra, con todas las columnas, salvo imbd_score] [labeltra, con ÃƒÂºnicamente la columna imbd_score]
# * (idem para datostst), y tenga en cuenta que debe realizar el mismo proceso con datosnor
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
labeltra = matrix(datostra$imdb_score)
index = match("imdb_score", names(datostra))
datostra = datostra[,-index]
datostst = datos[-trainIndex,]
labeltst = matrix(datostst$imdb_score)
index = match("imdb_score", names(datostst))
datostst = datostst[,-index]
trainIndex = createDataPartition(datosnor$duration, times = 1, p = 0.8, list = FALSE)
datostranor = datosnor[trainIndex,]
labeltranor = matrix(datostranor$imdb_score)
index = match("imdb_score", names(datostranor))
datostranor = datostranor[,-index]
datoststnor = datosnor[-trainIndex,]
labeltstnor = matrix(datoststnor$imdb_score)
index = match("imdb_score", names(datoststnor))
datoststnor = datoststnor[,-index]
# Paso 4: Aplique KNN con 3 valores de K diferentes (a su elecciÃƒÂ³n), para los datos normalizados y sin normalizar
# --> prediccion1 = knn(datostra, datostst, labeltra, k = XX)
# --> prediccion2 = knn(datostranor, datoststnor, labeltranor, k = XX)
# (hasta 6)
prediccion1 = knn(datostra, datostst, labeltra, k=10)
prediccion2 = knn(datostra, datostst, labeltra, k=1)
prediccion3 = knn(datostra, datostst, labeltra, k=5)
table(prediccion1)
table(prediccion2)
table(prediccion3)
prediccion4 = knn(datostranor, datoststnor, labeltranor, k=10)
prediccion5 = knn(datostranor, datoststnor, labeltranor, k=1)
prediccion6 = knn(datostranor, datoststnor, labeltranor, k=5)
table(prediccion4)
table(prediccion5)
table(prediccion6)
View(labeltranor)
labeltranor = datostranor$imdb_score
datos = read.csv("datos/movie_metadata.csv")
datos = na.omit(datos)
datos = datos[,sapply(datos, is.numeric)]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
# Paso 2: Cree una copia de los datos llamada "datosnor" y normalizela
# * Puede usar la funciÃƒÂ³n "data.Normalization()", dentro del paquete "clusterSim"
# * ojo, lea la documentaciÃƒÂ³n para ver quÃƒÂ© valor tiene que darle al parÃƒÂ¡metro "type"
# * Cuidado, te darÃƒÂ¡ error si intentas normalizarlo todo, ya que imbd_score no es numÃƒÂ©rica
index = match("imdb_score", names(datos))
datosnor = datos[,-index]
datosnor = data.Normalization(datosnor,"n8","column")
datosnor$imdb_score = datos$imdb_score;
# Paso 3: (igual que antes) utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#   en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
# * Ojo, para ejecutar KNN la clase tiene que estar por un lado, y la columna a predecir separada, por otro
# * por ello, deberÃƒÂ¡ partir datostra en [datostra, con todas las columnas, salvo imbd_score] [labeltra, con ÃƒÂºnicamente la columna imbd_score]
# * (idem para datostst), y tenga en cuenta que debe realizar el mismo proceso con datosnor
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
labeltra = datostra$imdb_score
index = match("imdb_score", names(datostra))
datostra = datostra[,-index]
datostst = datos[-trainIndex,]
labeltst = datostst$imdb_score
index = match("imdb_score", names(datostst))
datostst = datostst[,-index]
trainIndex = createDataPartition(datosnor$duration, times = 1, p = 0.8, list = FALSE)
datostranor = datosnor[trainIndex,]
labeltranor = datostranor$imdb_score
index = match("imdb_score", names(datostranor))
datostranor = datostranor[,-index]
datoststnor = datosnor[-trainIndex,]
labeltstnor = datoststnor$imdb_score
index = match("imdb_score", names(datoststnor))
datoststnor = datoststnor[,-index]
# Paso 4: Aplique KNN con 3 valores de K diferentes (a su elecciÃƒÂ³n), para los datos normalizados y sin normalizar
# --> prediccion1 = knn(datostra, datostst, labeltra, k = XX)
# --> prediccion2 = knn(datostranor, datoststnor, labeltranor, k = XX)
# (hasta 6)
prediccion1 = knn(datostra, datostst, labeltra, k=10)
prediccion2 = knn(datostra, datostst, labeltra, k=1)
prediccion3 = knn(datostra, datostst, labeltra, k=5)
table(prediccion1)
table(prediccion2)
table(prediccion3)
prediccion4 = knn(datostranor, datoststnor, labeltranor, k=10)
prediccion5 = knn(datostranor, datoststnor, labeltranor, k=1)
prediccion6 = knn(datostranor, datoststnor, labeltranor, k=5)
table(prediccion4)
table(prediccion5)
table(prediccion6)
# Paso 5: Calcule el porcentaje de aciertos de cada uno de los 6 modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, labeltra)
# Paso 5: Calcule el porcentaje de aciertos de cada uno de los 6 modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, labeltst)
aciertosModelo2 = confusionMatrix(prediccion2, labeltst)
aciertosModelo3 = confusionMatrix(prediccion3, labeltst)
aciertosModelo1
aciertosModelo2
aciertosModelo3
aciertosModelo4 = confusionMatrix(prediccion4, labeltstnor)
aciertosModelo5 = confusionMatrix(prediccion5, labeltstnor)
aciertosModelo6 = confusionMatrix(prediccion6, labeltstnor)
aciertosModelo4
aciertosModelo5
aciertosModelo6
rm(list = ls());cat("\014")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# (incluya aquÃƒ­ cualquier librerÃƒ­a a utilizar)
library(dplyr)
library(lattice)
library(ggplot2)
library(caret)
library(e1071)
library(clusterSim)
library(class)
library(arules)
#---------------------------------------------------------------------------
#---------------------------------------------------------------------------
######################## Parte 1 ###########################################
#---------------------------------------------------------------------------
# Paso 1: Utilice la funciÃƒÂ³n read.csv para leer el contenido del fichero "movie_metadata.csv"
#     AdemÃƒÂ¡s, elimine las siguientes columnas: "director_name", "actor_2_name", "actor_1_name"
#     "movie_title", "plot_keywords", "movie_imdb_link"
# ** Puede automatizar el proceso si intenta eliminar todas las columnas que sean de
#    tipo factor, y que ademÃƒÂ¡s, tengan mÃƒÂ¡s de 100 niveles diferentes
datos = read.csv("datos/movie_metadata.csv")
datos = dplyr::select(datos, -director_name, -actor_2_name, -actor_1_name, -movie_title, -plot_keywords, -movie_imdb_link)
# Paso 2: Discretice la columna imbd_score para tener rangos en [0, 7.5) [7.5, 9) y [9, 10]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
# Paso 3: QuÃƒÂ©date ÃƒÂºnicamente con las filas que tienen todos los datos (no tienen NAs)
datos = na.omit(datos)
# Paso 4: utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#         en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
datostst = datos[-trainIndex,]
# Paso 5: Llame a la funciÃƒÂ³n naiveBayes, de la librerÃƒ­a "e1071" para entrenar el modelo con los
# datos de entrenamiento (datostra)
# --> modelo1=naiveBayes(........)
modelo1 = naiveBayes(imdb_score ~ ., datostra, laplace = 0)
# Paso 6: Llame a la funciÃƒÂ³n naiveBayes para entrenar un modelo2, utilizando el parÃƒÂ¡metro que aplica
# la correcciÃƒÂ³n de Laplace
# --> modelo2=naiveBayes(...)
modelo2 = naiveBayes(imdb_score ~ ., datostra, laplace = 3)
# Paso 7: Realice predicciones sobre los datos de test (datostst) de los dos modelos con el comando predict
# --> prediccion1=predict(modelo1,...)
# --> prediccion2=predict(modelo2,...)
prediccion1 = predict(modelo1, datostst)
prediccion2 = predict(modelo2, datostst)
table(prediccion1)
table(prediccion2)
# Paso 8: Calcule el porcentaje de aciertos de cada uno de los modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, datostst$imdb_score)
aciertosModelo2 = confusionMatrix(prediccion2, datostst$imdb_score)
aciertosModelo1
aciertosModelo2
#---------------------------------------------------------------------------
######################## Parte 2 ###########################################
#---------------------------------------------------------------------------
# Paso 1: Utilice la funciÃƒÂ³n read.csv para leer el contenido del fichero "movie_metadata.csv" (igual que antes)
# En este caso, elimine toda columna que no sea numÃƒÂ©rica y toda fila que tenga algÃƒÂºn valor perdido.
# Discretice la columna imbd_score igual que antes
# * Puede utilizar los comandos is.numeric()
# * EstÃƒÂ¡ permitido eliminar "manualmente" las columnas, pero no es elegante
datos = read.csv("datos/movie_metadata.csv")
datos = na.omit(datos)
datos = datos[,sapply(datos, is.numeric)]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
# Paso 2: Cree una copia de los datos llamada "datosnor" y normalizela
# * Puede usar la funciÃƒÂ³n "data.Normalization()", dentro del paquete "clusterSim"
# * ojo, lea la documentaciÃƒÂ³n para ver quÃƒÂ© valor tiene que darle al parÃƒÂ¡metro "type"
# * Cuidado, te darÃƒÂ¡ error si intentas normalizarlo todo, ya que imbd_score no es numÃƒÂ©rica
index = match("imdb_score", names(datos))
datosnor = datos[,-index]
datosnor = data.Normalization(datosnor,"n8","column")
datosnor$imdb_score = datos$imdb_score;
# Paso 3: (igual que antes) utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#   en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
# * Ojo, para ejecutar KNN la clase tiene que estar por un lado, y la columna a predecir separada, por otro
# * por ello, deberÃƒÂ¡ partir datostra en [datostra, con todas las columnas, salvo imbd_score] [labeltra, con ÃƒÂºnicamente la columna imbd_score]
# * (idem para datostst), y tenga en cuenta que debe realizar el mismo proceso con datosnor
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
labeltra = datostra$imdb_score
index = match("imdb_score", names(datostra))
datostra = datostra[,-index]
datostst = datos[-trainIndex,]
labeltst = datostst$imdb_score
index = match("imdb_score", names(datostst))
datostst = datostst[,-index]
trainIndex = createDataPartition(datosnor$duration, times = 1, p = 0.8, list = FALSE)
datostranor = datosnor[trainIndex,]
labeltranor = datostranor$imdb_score
index = match("imdb_score", names(datostranor))
datostranor = datostranor[,-index]
datoststnor = datosnor[-trainIndex,]
labeltstnor = datoststnor$imdb_score
index = match("imdb_score", names(datoststnor))
datoststnor = datoststnor[,-index]
# Paso 4: Aplique KNN con 3 valores de K diferentes (a su elecciÃƒÂ³n), para los datos normalizados y sin normalizar
# --> prediccion1 = knn(datostra, datostst, labeltra, k = XX)
# --> prediccion2 = knn(datostranor, datoststnor, labeltranor, k = XX)
# (hasta 6)
prediccion1 = knn(datostra, datostst, labeltra, k=10)
prediccion2 = knn(datostra, datostst, labeltra, k=1)
prediccion3 = knn(datostra, datostst, labeltra, k=5)
table(prediccion1)
table(prediccion2)
table(prediccion3)
prediccion4 = knn(datostranor, datoststnor, labeltranor, k=10)
prediccion5 = knn(datostranor, datoststnor, labeltranor, k=1)
prediccion6 = knn(datostranor, datoststnor, labeltranor, k=5)
table(prediccion4)
table(prediccion5)
table(prediccion6)
# Paso 5: Calcule el porcentaje de aciertos de cada uno de los 6 modelos. Ã‚Â¿CuÃƒÂ¡l es mejor? Razone por quÃƒÂ©
# *Nota: puede utilizar, si le es mÃƒÂ¡s cÃƒÂ³modo el comando confusionMatrix, de la librerÃƒ­a "caret"
aciertosModelo1 = confusionMatrix(prediccion1, labeltst)
aciertosModelo2 = confusionMatrix(prediccion2, labeltst)
aciertosModelo3 = confusionMatrix(prediccion3, labeltst)
aciertosModelo1
aciertosModelo1 = confusionMatrix(prediccion1, labeltst)
aciertosModelo2 = confusionMatrix(prediccion2, labeltst)
aciertosModelo3 = confusionMatrix(prediccion3, labeltst)
aciertosModelo2
aciertosModelo3
aciertosModelo4 = confusionMatrix(prediccion4, labeltstnor)
aciertosModelo5 = confusionMatrix(prediccion5, labeltstnor)
aciertosModelo6 = confusionMatrix(prediccion6, labeltstnor)
aciertosModelo4
aciertosModelo5
aciertosModelo6
datos = read.csv("datos/movie_metadata.csv")
datos = dplyr::select(datos, -director_name, -actor_2_name, -actor_1_name, -movie_title, -plot_keywords, -movie_imdb_link)
# Paso 2: Discretice la columna imbd_score para tener rangos en [0, 7.5) [7.5, 9) y [9, 10]
datos$imdb_score = discretize(datos$imdb_score, "fixed", breaks = c(0,7.5,9,10))
# Paso 3: QuÃƒÂ©date ÃƒÂºnicamente con las filas que tienen todos los datos (no tienen NAs)
datos = na.omit(datos)
# Paso 4: utilice el mÃƒÂ©todo "createDataPartition", de la librerÃƒ­a "caret" para partir los datos
#         en 2 pedazos-> [datostra, con el 80% de los datos] [datostst con el 20% restante]
trainIndex = createDataPartition(datos$duration, times = 1, p = 0.8, list = FALSE)
datostra = datos[trainIndex,]
datostst = datos[-trainIndex,]
# Paso 5: Llame a la funciÃƒÂ³n naiveBayes, de la librerÃƒ­a "e1071" para entrenar el modelo con los
# datos de entrenamiento (datostra)
# --> modelo1=naiveBayes(........)
modelo1 = naiveBayes(imdb_score ~ ., datostra, laplace = 0)
# Paso 6: Llame a la funciÃƒÂ³n naiveBayes para entrenar un modelo2, utilizando el parÃƒÂ¡metro que aplica
# la correcciÃƒÂ³n de Laplace
# --> modelo2=naiveBayes(...)
modelo2 = naiveBayes(imdb_score ~ ., datostra, laplace = 3)
# Paso 7: Realice predicciones sobre los datos de test (datostst) de los dos modelos con el comando predict
# --> prediccion1=predict(modelo1,...)
# --> prediccion2=predict(modelo2,...)
prediccion1 = predict(modelo1, datostst)
prediccion2 = predict(modelo2, datostst)
table(prediccion1)
table(prediccion2)
aciertosModelo1 = confusionMatrix(prediccion1, datostst$imdb_score)
aciertosModelo2 = confusionMatrix(prediccion2, datostst$imdb_score)
aciertosModelo1
aciertosModelo2
